# DSPy Follow-ups for Library Cards Benchmark

## Currently being implemented (see plan)

Items 1, 3, 4 below are implemented as experiments E1–E3.
All use Gemini 2.5 Pro. Total estimated cost: ~$42–55.

### 1. ChainOfThought (E1 baseline + E2 optimized)

Replace dspy.Predict with dspy.ChainOfThought — forces step-by-step
reasoning before producing JSON. Should help with tricky decisions like
the "s." marker for type classification, or distinguishing shelfmark
from subjects. Implemented via --module cot flag on all scripts.

### 3. MIPROv2 medium (E2)

Increase optimization budget from auto="light" (6 candidates) to
auto="medium" (12 candidates). The light run already found a strong
program (0.8912); a broader search may find something better.

### 4. dspy.Refine wrapper (E3)

Wraps the optimized module at inference time. When the output fails
structural validation (bad JSON or missing required keys), Refine
retries up to N times with LM-generated feedback. Costs extra calls
only on failures. Uses refine_reward_fn in src/scoring.py.

Note: Refine forces temperature=1.0 for diversity, so E3 is not a
strict superset of E2 — first attempts may produce different outputs.

---

## To investigate next

### 2. Cross-model transfer evaluation

The optimized program stores "lm": null — it works with any model.
Run the Gemini-optimized program on other models to see transfer:

  uv run python scripts/evaluate_optimized.py \
    --program results/optimized/mipro-cot_gemini-2.5-pro_optimized.json \
    --model claude-sonnet --module cot

  uv run python scripts/evaluate_optimized.py \
    --program results/optimized/mipro-cot_gemini-2.5-pro_optimized.json \
    --model gpt-4o --module cot

DSPy community recommends re-optimizing per model for best results
(optimized instructions partially transfer but are not optimal). A
2x2 matrix would be informative:
  - Gemini-optimized program on Gemini / Claude / GPT-4o
  - Per-model re-optimization on each

Note: use the --module flag matching how the program was optimized
(cot programs need --module cot, predict programs need --module predict).

### 5. Per-model re-optimization

After cross-model eval, re-optimize for the best-performing model.
Can use the existing optimized program as a warm start. Rate limit
considerations: Gemini 2.5 Pro has generous limits (1M+ TPM); GPT-4o
has 30K TPM (struggled in initial runs); Claude pricing/limits untested.

---

## Further techniques to explore

### dspy.BestOfN

Like Refine but without iterative feedback — just runs N times and
picks the best output by reward score. Cheaper than Refine (no feedback
LM calls) but also less targeted. Useful baseline comparison for Refine.
Same reward_fn and threshold interface.

### GEPA optimizer

Genetic-evolutionary optimizer that uses textual feedback to guide
prompt improvement. Our scoring.py already produces rich per-field
scores (which fields matched, fuzzy scores, TP/FP/FN). GEPA can
leverage this feedback signal. Requires a feedback_metric that returns
{"score": float, "feedback": str} instead of just a float. Would need
a small wrapper around dspy_metric.

### SIMBA optimizer

Focuses on failure cases. Identifies the hardest examples, introspects
on why they fail, generates targeted improvement rules. Good complement
to MIPROv2 which optimizes for average performance. Usage:
  from dspy.teleprompt import SIMBA
  simba = SIMBA(metric=dspy_metric, max_steps=12, max_demos=10)

### Multi-stage pipeline

Break extraction into two DSPy modules chained together:
  1. card_image -> card_description (vision/OCR step)
  2. card_description -> document (structuring step)

DSPy optimizers optimize ALL stages holistically via the end-to-end
metric. Separates vision errors from structuring errors, making
debugging easier. But doubles LM calls per card.

### BootstrapFewShotWithRandomSearch

Straightforward upgrade from BootstrapFewShot — searches over more
program variants via random search. Already supported in DSPy 3.1.3.

### KNNFewShot

Selects different few-shot demos per input based on similarity. Could
help if different card types (dissertation vs reference) benefit from
different demonstrations.

### BootstrapFinetune

Uses a strong model as teacher to generate training data, then
finetunes a cheaper model. Path to production deployment but requires
finetuning infrastructure. Not relevant for benchmark evaluation but
worth noting for practical adoption.

---

## Notes

- DSPy version installed: 3.1.3
- dspy.Assert / dspy.Suggest are deprecated — replaced by Refine / BestOfN
- ChainOfThought and Predict save different state keys ("predict.predict"
  vs "predict"), so optimized programs are NOT interchangeable between
  module types. Always use matching --module flag.
- MIPROv2 auto presets: light=6 candidates, medium=12, heavy=18.
  Manual override also possible via num_candidates/num_trials params.
